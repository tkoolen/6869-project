#LyX 2.1 created this file. For more info see http://www.lyx.org/
\lyxformat 474
\begin_document
\begin_header
\textclass article
\use_default_options true
\maintain_unincluded_children false
\language english
\language_package default
\inputencoding auto
\fontencoding global
\font_roman default
\font_sans default
\font_typewriter default
\font_math auto
\font_default_family default
\use_non_tex_fonts false
\font_sc false
\font_osf false
\font_sf_scale 100
\font_tt_scale 100
\graphics default
\default_output_format default
\output_sync 0
\bibtex_command default
\index_command default
\paperfontsize default
\spacing single
\use_hyperref false
\papersize default
\use_geometry true
\use_package amsmath 1
\use_package amssymb 1
\use_package cancel 1
\use_package esint 1
\use_package mathdots 1
\use_package mathtools 1
\use_package mhchem 1
\use_package stackrel 1
\use_package stmaryrd 1
\use_package undertilde 1
\cite_engine basic
\cite_engine_type default
\biblio_style plain
\use_bibtopic false
\use_indices false
\paperorientation portrait
\suppress_date false
\justification true
\use_refstyle 1
\index Index
\shortcut idx
\color #008000
\end_index
\leftmargin 1in
\topmargin 1in
\rightmargin 1in
\bottommargin 1in
\secnumdepth 3
\tocdepth 3
\paragraph_separation indent
\paragraph_indentation default
\quotes_language english
\papercolumns 1
\papersides 1
\paperpagestyle default
\tracking_changes false
\output_changes false
\html_math_output 0
\html_css_as_file 0
\html_be_strict false
\end_header

\begin_body

\begin_layout Section
Introduction
\end_layout

\begin_layout Standard
Motion estimation is the task of inferring motion information for each pixel
 from the frames of a video.
 One approach infers this information from the motion of the brightness
 patterns across the frames, which are typically correlated with the underlying
 motion.
 The motion of the brightness pattern is known as optical flow, and we refer
 to the optical flow of an individual pixel as its flow vector.
 
\end_layout

\begin_layout Standard
In their seminal work 
\begin_inset CommandInset citation
LatexCommand cite
key "horn1981determining"

\end_inset

, Horne and Schunck developed an algorithm to estimate optical flow from
 a sequence of brightness patterns.
 To estimate optical flow, Horne and Schunck make two assumptions.
 They first assume brightness constancy in the frame sequences.
 Over a short duration, the brightness at 
\begin_inset ERT
status open

\begin_layout Plain Layout

$(x, y)$
\end_layout

\end_inset

 in one frame is equal the brightness at the corresponding location 
\begin_inset ERT
status open

\begin_layout Plain Layout

$(x',y')$
\end_layout

\end_inset

 in the following frame.
 Second, they also assume that the flow vectors vary continuously across
 the frame.
 Combining both assumptions, for each pixel, the flow vector is the solution
 to the following optimization problem: 
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{eqnarray}
(u_{i,j},v_{i,j}) & = & \arg\min_{u,v}\lambda(I_{x}u+I_{y}v+I_{t})^{2}+\nonumber \\
 &  & \frac{1}{4}((u_{i+1,j}-u)^{2}+(u_{i,j+1}-u)^{2}+(v_{i+1,j}-v)^{2}+(v_{i,j+1}-v)^{2})\label{eq:of_formulation}
\end{eqnarray}

\end_inset

Here, 
\begin_inset ERT
status open

\begin_layout Plain Layout

$u_{i,j}$
\end_layout

\end_inset

 and 
\begin_inset ERT
status open

\begin_layout Plain Layout

$v_{i,j}$
\end_layout

\end_inset

 represent the 
\begin_inset ERT
status open

\begin_layout Plain Layout

$x$
\end_layout

\end_inset

 and 
\begin_inset ERT
status open

\begin_layout Plain Layout

$y$
\end_layout

\end_inset

 components of the flow vector for the 
\begin_inset ERT
status open

\begin_layout Plain Layout

$(i,j)$
\end_layout

\end_inset

 pixel, respectively; 
\begin_inset ERT
status open

\begin_layout Plain Layout

$I_x$
\end_layout

\end_inset

, 
\begin_inset ERT
status open

\begin_layout Plain Layout

$I_y$
\end_layout

\end_inset

, 
\begin_inset ERT
status open

\begin_layout Plain Layout

$I_t$
\end_layout

\end_inset

 represent the derivatives of the image brightness with respect to 
\begin_inset ERT
status open

\begin_layout Plain Layout

$x$
\end_layout

\end_inset

, 
\begin_inset ERT
status open

\begin_layout Plain Layout

$y$
\end_layout

\end_inset

, and 
\begin_inset ERT
status open

\begin_layout Plain Layout

$t$
\end_layout

\end_inset

, respectively; and 
\begin_inset ERT
status open

\begin_layout Plain Layout

$
\backslash
lambda$
\end_layout

\end_inset

 represent the regularizing term.
 We set the derivative of (
\begin_inset CommandInset ref
LatexCommand ref
reference "eq:of_formulation"

\end_inset

) with respect to 
\begin_inset ERT
status open

\begin_layout Plain Layout

$u_{i,j}$ and $v_{i,j}$
\end_layout

\end_inset

 to 0 and obtain the following iterative solution:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{eqnarray}
u_{i,j}^{n+1} & = & \bar{u}_{i,j}^{n}-\frac{I_{x}\bar{u}_{i,j}^{n}+I_{y}\bar{v}_{i,j}^{n}+I_{t}}{1+\lambda(I_{x}^{2}+I_{y}^{2})}I_{x}\label{eq:u_update}
\end{eqnarray}

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{eqnarray}
v_{i,j}^{n+1} & = & \bar{v}_{i,j}^{n}-\frac{I_{x}\bar{u}_{i,j}^{n}+I_{y}\bar{v}_{i,j}^{n}+I_{t}}{1+\lambda(I_{x}^{2}+I_{y}^{2})}I_{y}\label{eq:v_update}
\end{eqnarray}

\end_inset

where 
\begin_inset ERT
status open

\begin_layout Plain Layout

$
\backslash
bar{u}_{i,j}=
\backslash
frac{1}{2}(u_{i+1,j}+u_{i,j+1})$
\end_layout

\end_inset

 and 
\begin_inset ERT
status open

\begin_layout Plain Layout

$
\backslash
bar{v}_{i,j}=
\backslash
frac{1}{2}(v_{i+1,j}+v_{i,j+1})$
\end_layout

\end_inset

.
 For a detailed treatment of this derivation, please see 
\begin_inset CommandInset citation
LatexCommand cite
key "machinvevision"

\end_inset

.
\end_layout

\begin_layout Subsection
Benchmark Dataset
\end_layout

\begin_layout Standard
We evaluate the resulting optical flow against the Middlebury optical flow
 benchmark dataset.
 The Middlebury dataset is composed of 24 image sequences that represent
 four distinct classes: (1) non-rigid motion, (2) synthetic objects, (3)
 high frame-rate video, and (4) stereo scene images 
\begin_inset CommandInset citation
LatexCommand cite
key "baker2011database"

\end_inset

.
 
\end_layout

\begin_layout Subsection
Evaluation Metrics
\end_layout

\begin_layout Standard
We define two metrics to compare the optical flow with the ground truth
 motion vector: angular error (AE) and endpoint error (EE) 
\begin_inset CommandInset citation
LatexCommand cite
key "baker2011database"

\end_inset

.
 Denoting the ground truth motion vector as 
\begin_inset ERT
status open

\begin_layout Plain Layout

$(u_{GT}, v_{GT})^T$
\end_layout

\end_inset

, AE is defined as:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{eqnarray}
AE & = & \arccos\left(\frac{1+u\cdot u_{GT}+v\cdot v_{GT}}{\sqrt{1+u^{2}+v^{2}}\sqrt{1+u_{GT}^{2}+v_{GT}^{2}}}\right)\label{eq:AE_metric}
\end{eqnarray}

\end_inset

Similarly, EE is defined as:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{eqnarray}
EE & = & \sqrt{(u-u_{GT})^{2}+(v-v_{GT})^{2}}\label{eq:EE_metric}
\end{eqnarray}

\end_inset


\end_layout

\begin_layout Section
Our Work
\end_layout

\begin_layout Standard
The key contributions in 
\begin_inset CommandInset citation
LatexCommand cite
key "sun2014quantitative"

\end_inset

 improves on 
\begin_inset CommandInset citation
LatexCommand cite
key "horn1981determining"

\end_inset

 by: changing the quadratic penalty to a non-convex generalized Charbonnier
 function, applying median filtering in intermediate stages and using spline-bas
ed bicubic interpolation in the coarse-to-fine optimization.
 Here, we propose the following explorations to improve the median filter
 and the coarse-to-fine optimization presented in 
\begin_inset CommandInset citation
LatexCommand cite
key "sun2014quantitative"

\end_inset

.
\end_layout

\begin_layout Standard

\end_layout

\begin_layout Paragraph
Weighted Median Filter
\end_layout

\begin_layout Standard
In the intermediate stages of the coarse-to-fine optimization, a median
 filter is applied.
 In highly structred regions (e.g.
 edges), median filtering can oversmooth and remove features.
 We will explore weighted median filtering in the intermediate stages by
 varying the weight allocations for each pixel in the median block.
 Once we gain an intuition on the effects of the different weights, we will
 attempt to understand how to automatically assign weights to the median
 filter based on image features and statistics.
 We will compare the results here to 
\begin_inset CommandInset citation
LatexCommand cite
key "sun2014quantitative"

\end_inset

 to see how our approach compares to their optimization strategy.
\end_layout

\begin_layout Paragraph
Speeding up Coarse-to-Fine Optimization
\end_layout

\begin_layout Standard
In the current pipeline used to determine optical flow, we compute the optical
 flow for each intermediate stage.
 Due to the overhead of computing flow vectors for each intermediate stage,
 we will explore an alternative approach of using block matching in the
 coarser optimization stages.
 In block matching, we subdivide the frame into NxN blocks and find their
 corresponding motion vectors.
 There is a rich literature of block matching algorithms that are optimized
 for speed 
\begin_inset CommandInset citation
LatexCommand cite
key "lin1997fast,jain1981displacement"

\end_inset

.
 Here, we will compare the accuracy of using block matching in intermediate
 steps and optical flow in the final estimation to 
\begin_inset CommandInset citation
LatexCommand cite
key "sun2014quantitative"

\end_inset

 to determine a tradeoff between computational complexity and accuracy.
\end_layout

\begin_layout Paragraph
Evaluation
\end_layout

\begin_layout Standard
We will use both simple sequences (e.g.
 red square moving against a white background) and the Middlebury dataset
 to quantify our results.
\end_layout

\begin_layout Standard
\begin_inset CommandInset bibtex
LatexCommand bibtex
bibfiles "/Users/james/Dropbox/project/references/references"
options "plain"

\end_inset


\end_layout

\end_body
\end_document
